{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study: Classify songs into different genres\n",
    "# Objective: Model a classifier to classify songs into different genres.\n",
    "# Dataset: GITZAN dataset\n",
    "# Preprocessing the data: Before training the classification model, we have to transform\n",
    "#                           raw data from audio samples into more meaningful representations.\n",
    "#                           The audio clips need to be converted from .au format to .wav format\n",
    "#                           to make it compatible with python's wave module for reading audio\n",
    "#                           files. If needed to convert, use sox input.au output.wav. \n",
    "#                           link: https://www.stefaanlippens.net/audio_conversion_cheat_sheet/\n",
    "# Classification:\n",
    "#   Feature Extraction: We need to extract meaningful features from audio files. To classify \n",
    "#                       audio clips, we will choose five features, i.e. Mel-Frequency Cepstral\n",
    "#                       Coefficients, Spectral Centroid, Zero Crossing Rate, Chroma Frequencies,\n",
    "#                       Spectral Roll-off. All of the features are then appended into a .csv file\n",
    "#                       so that classification algorithms can be used.\n",
    "#   Classification: Once the features have been extracted, we can use existing classification\n",
    "#                   algorithms to classify the songs into different genres. You can either use the\n",
    "#                   spectogram images directly for classification or you can extract the features\n",
    "#                   and use the classification models on them. Usig a CNN model (on the spectogram\n",
    "#                   images) gives a better accuracy.\n",
    "# Source: https://gist.github.com/parulnith/7f8c174e6ac099e86f0495d3d9a4c01e\n",
    "\n",
    "# Importing libraries\n",
    "# Feature extracting and Preprocessing data\n",
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Extracting music and features\n",
    "\n",
    "# Extracting the Spectrogram for every audio. All the files get converted into their respective\n",
    "# spectograms. We can easily extract features from them.\n",
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./genres/{g}'):\n",
    "        songname = f'./genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from Spectogram\n",
    "# We will extract:\n",
    "#   Mel-frequency cepstral coefficients (MFCC)(20 in number)\n",
    "#   Spectral Centroid\n",
    "#   Zero Crossing Rate\n",
    "#   Chroma Frequencies\n",
    "#   Spectral Roll-off\n",
    "\n",
    "header = 'filename chroma_stft rms spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data to a csv file\n",
    "\n",
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./genres/{g}'):\n",
    "        songname = f'./genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00093.wav     0.377690  0.065906         569.930721   \n",
       "1  blues.00087.wav     0.336773  0.158098        1442.190271   \n",
       "2  blues.00050.wav     0.400860  0.182380        1945.848425   \n",
       "3  blues.00044.wav     0.390212  0.136276        2279.124558   \n",
       "4  blues.00078.wav     0.414188  0.258052        2333.685108   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0          995.407125   927.427725            0.021701 -350.436188   \n",
       "1         1870.534155  3083.414688            0.050889 -155.504929   \n",
       "2         2082.246626  4175.874749            0.085806  -82.979019   \n",
       "3         2375.102120  5198.360233            0.092570 -109.509285   \n",
       "4         2227.425609  4942.811778            0.123863   -2.524338   \n",
       "\n",
       "        mfcc2      mfcc3  ...     mfcc12     mfcc13    mfcc14     mfcc15  \\\n",
       "0  169.545746  31.820370  ...   1.821690  -5.970891 -5.259567  -0.229211   \n",
       "1  125.638863   1.596553  ...  -0.792893  -7.748057  0.413548  -7.030262   \n",
       "2  107.052124 -25.320452  ...  12.539581  -9.762303  2.562253  -6.300853   \n",
       "3   86.922409  -8.607986  ...  11.087481  -5.085794  3.976360 -12.859742   \n",
       "4  101.252716 -33.924385  ...  12.506608 -13.368823  6.112817  -9.065890   \n",
       "\n",
       "      mfcc16     mfcc17    mfcc18    mfcc19    mfcc20  label  \n",
       "0  -1.776850  -3.713751  0.181591  2.072390 -2.896225  blues  \n",
       "1   3.997679  -6.256611  0.958227  2.019821 -5.742188  blues  \n",
       "2   2.996785  -8.718454 -0.326581 -2.980347  0.712601  blues  \n",
       "3  12.343859   0.026216 -0.741568 -5.126620  3.303442  blues  \n",
       "4   5.033774 -11.330277  3.166534 -4.567591 -4.033622  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>chroma_stft</th>\n      <th>rmse</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc1</th>\n      <th>mfcc2</th>\n      <th>mfcc3</th>\n      <th>...</th>\n      <th>mfcc12</th>\n      <th>mfcc13</th>\n      <th>mfcc14</th>\n      <th>mfcc15</th>\n      <th>mfcc16</th>\n      <th>mfcc17</th>\n      <th>mfcc18</th>\n      <th>mfcc19</th>\n      <th>mfcc20</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>blues.00093.wav</td>\n      <td>0.377690</td>\n      <td>0.065906</td>\n      <td>569.930721</td>\n      <td>995.407125</td>\n      <td>927.427725</td>\n      <td>0.021701</td>\n      <td>-350.436188</td>\n      <td>169.545746</td>\n      <td>31.820370</td>\n      <td>...</td>\n      <td>1.821690</td>\n      <td>-5.970891</td>\n      <td>-5.259567</td>\n      <td>-0.229211</td>\n      <td>-1.776850</td>\n      <td>-3.713751</td>\n      <td>0.181591</td>\n      <td>2.072390</td>\n      <td>-2.896225</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blues.00087.wav</td>\n      <td>0.336773</td>\n      <td>0.158098</td>\n      <td>1442.190271</td>\n      <td>1870.534155</td>\n      <td>3083.414688</td>\n      <td>0.050889</td>\n      <td>-155.504929</td>\n      <td>125.638863</td>\n      <td>1.596553</td>\n      <td>...</td>\n      <td>-0.792893</td>\n      <td>-7.748057</td>\n      <td>0.413548</td>\n      <td>-7.030262</td>\n      <td>3.997679</td>\n      <td>-6.256611</td>\n      <td>0.958227</td>\n      <td>2.019821</td>\n      <td>-5.742188</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blues.00050.wav</td>\n      <td>0.400860</td>\n      <td>0.182380</td>\n      <td>1945.848425</td>\n      <td>2082.246626</td>\n      <td>4175.874749</td>\n      <td>0.085806</td>\n      <td>-82.979019</td>\n      <td>107.052124</td>\n      <td>-25.320452</td>\n      <td>...</td>\n      <td>12.539581</td>\n      <td>-9.762303</td>\n      <td>2.562253</td>\n      <td>-6.300853</td>\n      <td>2.996785</td>\n      <td>-8.718454</td>\n      <td>-0.326581</td>\n      <td>-2.980347</td>\n      <td>0.712601</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>blues.00044.wav</td>\n      <td>0.390212</td>\n      <td>0.136276</td>\n      <td>2279.124558</td>\n      <td>2375.102120</td>\n      <td>5198.360233</td>\n      <td>0.092570</td>\n      <td>-109.509285</td>\n      <td>86.922409</td>\n      <td>-8.607986</td>\n      <td>...</td>\n      <td>11.087481</td>\n      <td>-5.085794</td>\n      <td>3.976360</td>\n      <td>-12.859742</td>\n      <td>12.343859</td>\n      <td>0.026216</td>\n      <td>-0.741568</td>\n      <td>-5.126620</td>\n      <td>3.303442</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>blues.00078.wav</td>\n      <td>0.414188</td>\n      <td>0.258052</td>\n      <td>2333.685108</td>\n      <td>2227.425609</td>\n      <td>4942.811778</td>\n      <td>0.123863</td>\n      <td>-2.524338</td>\n      <td>101.252716</td>\n      <td>-33.924385</td>\n      <td>...</td>\n      <td>12.506608</td>\n      <td>-13.368823</td>\n      <td>6.112817</td>\n      <td>-9.065890</td>\n      <td>5.033774</td>\n      <td>-11.330277</td>\n      <td>3.166534</td>\n      <td>-4.567591</td>\n      <td>-4.033622</td>\n      <td>blues</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Analysing the data in Pandas\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
       "0     0.377690  0.065906         569.930721          995.407125   927.427725   \n",
       "1     0.336773  0.158098        1442.190271         1870.534155  3083.414688   \n",
       "2     0.400860  0.182380        1945.848425         2082.246626  4175.874749   \n",
       "3     0.390212  0.136276        2279.124558         2375.102120  5198.360233   \n",
       "4     0.414188  0.258052        2333.685108         2227.425609  4942.811778   \n",
       "\n",
       "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
       "0            0.021701 -350.436188  169.545746  31.820370  16.682835  ...   \n",
       "1            0.050889 -155.504929  125.638863   1.596553  45.804520  ...   \n",
       "2            0.085806  -82.979019  107.052124 -25.320452  57.124989  ...   \n",
       "3            0.092570 -109.509285   86.922409  -8.607986  64.494560  ...   \n",
       "4            0.123863   -2.524338  101.252716 -33.924385  41.516888  ...   \n",
       "\n",
       "      mfcc12     mfcc13    mfcc14     mfcc15     mfcc16     mfcc17    mfcc18  \\\n",
       "0   1.821690  -5.970891 -5.259567  -0.229211  -1.776850  -3.713751  0.181591   \n",
       "1  -0.792893  -7.748057  0.413548  -7.030262   3.997679  -6.256611  0.958227   \n",
       "2  12.539581  -9.762303  2.562253  -6.300853   2.996785  -8.718454 -0.326581   \n",
       "3  11.087481  -5.085794  3.976360 -12.859742  12.343859   0.026216 -0.741568   \n",
       "4  12.506608 -13.368823  6.112817  -9.065890   5.033774 -11.330277  3.166534   \n",
       "\n",
       "     mfcc19    mfcc20  label  \n",
       "0  2.072390 -2.896225  blues  \n",
       "1  2.019821 -5.742188  blues  \n",
       "2 -2.980347  0.712601  blues  \n",
       "3 -5.126620  3.303442  blues  \n",
       "4 -4.567591 -4.033622  blues  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chroma_stft</th>\n      <th>rmse</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc1</th>\n      <th>mfcc2</th>\n      <th>mfcc3</th>\n      <th>mfcc4</th>\n      <th>...</th>\n      <th>mfcc12</th>\n      <th>mfcc13</th>\n      <th>mfcc14</th>\n      <th>mfcc15</th>\n      <th>mfcc16</th>\n      <th>mfcc17</th>\n      <th>mfcc18</th>\n      <th>mfcc19</th>\n      <th>mfcc20</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.377690</td>\n      <td>0.065906</td>\n      <td>569.930721</td>\n      <td>995.407125</td>\n      <td>927.427725</td>\n      <td>0.021701</td>\n      <td>-350.436188</td>\n      <td>169.545746</td>\n      <td>31.820370</td>\n      <td>16.682835</td>\n      <td>...</td>\n      <td>1.821690</td>\n      <td>-5.970891</td>\n      <td>-5.259567</td>\n      <td>-0.229211</td>\n      <td>-1.776850</td>\n      <td>-3.713751</td>\n      <td>0.181591</td>\n      <td>2.072390</td>\n      <td>-2.896225</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.336773</td>\n      <td>0.158098</td>\n      <td>1442.190271</td>\n      <td>1870.534155</td>\n      <td>3083.414688</td>\n      <td>0.050889</td>\n      <td>-155.504929</td>\n      <td>125.638863</td>\n      <td>1.596553</td>\n      <td>45.804520</td>\n      <td>...</td>\n      <td>-0.792893</td>\n      <td>-7.748057</td>\n      <td>0.413548</td>\n      <td>-7.030262</td>\n      <td>3.997679</td>\n      <td>-6.256611</td>\n      <td>0.958227</td>\n      <td>2.019821</td>\n      <td>-5.742188</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.400860</td>\n      <td>0.182380</td>\n      <td>1945.848425</td>\n      <td>2082.246626</td>\n      <td>4175.874749</td>\n      <td>0.085806</td>\n      <td>-82.979019</td>\n      <td>107.052124</td>\n      <td>-25.320452</td>\n      <td>57.124989</td>\n      <td>...</td>\n      <td>12.539581</td>\n      <td>-9.762303</td>\n      <td>2.562253</td>\n      <td>-6.300853</td>\n      <td>2.996785</td>\n      <td>-8.718454</td>\n      <td>-0.326581</td>\n      <td>-2.980347</td>\n      <td>0.712601</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.390212</td>\n      <td>0.136276</td>\n      <td>2279.124558</td>\n      <td>2375.102120</td>\n      <td>5198.360233</td>\n      <td>0.092570</td>\n      <td>-109.509285</td>\n      <td>86.922409</td>\n      <td>-8.607986</td>\n      <td>64.494560</td>\n      <td>...</td>\n      <td>11.087481</td>\n      <td>-5.085794</td>\n      <td>3.976360</td>\n      <td>-12.859742</td>\n      <td>12.343859</td>\n      <td>0.026216</td>\n      <td>-0.741568</td>\n      <td>-5.126620</td>\n      <td>3.303442</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.414188</td>\n      <td>0.258052</td>\n      <td>2333.685108</td>\n      <td>2227.425609</td>\n      <td>4942.811778</td>\n      <td>0.123863</td>\n      <td>-2.524338</td>\n      <td>101.252716</td>\n      <td>-33.924385</td>\n      <td>41.516888</td>\n      <td>...</td>\n      <td>12.506608</td>\n      <td>-13.368823</td>\n      <td>6.112817</td>\n      <td>-9.065890</td>\n      <td>5.033774</td>\n      <td>-11.330277</td>\n      <td>3.166534</td>\n      <td>-4.567591</td>\n      <td>-4.033622</td>\n      <td>blues</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Labels\n",
    "\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Feature Columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data into training and Testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.14450761, -0.5242746 ,  1.03846878,  1.11969883,  1.12002066,\n",
       "        0.27079125,  0.13040426, -1.01642597,  1.92883368, -0.10208166,\n",
       "       -0.17273638,  0.61266362, -0.0686508 ,  0.0114033 , -0.00765423,\n",
       "       -0.68509775,  0.2422508 , -1.16213042, -0.24049213, -0.40162617,\n",
       "        0.38951325, -0.6641459 ,  0.67908619,  0.11503152,  0.21058462,\n",
       "       -0.01974234])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification with Keras\n",
    "# Relu - Applies the rectified linear unit activation function.\n",
    "# With default values, this returns the standard ReLU activation: max(x, 0), the element-wise maximum of 0 and the input tensor.\n",
    "# https://keras.io/api/layers/activations/\n",
    "# Softmax - The softmax function, also known as softargmax[1]:184 or normalized exponential function,[2]:198 is a generalization of the logistic \n",
    "# function to multiple dimensions. It is used in multinomial logistic regression and is often used as the last activation function of a neural \n",
    "# network to normalize the output of a network to a probability distribution over predicted output classes, based on Luce's choice axiom.\n",
    "# https://en.wikipedia.org/wiki/Softmax_function\n",
    "\n",
    "# Building our Network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config the model with losses and metrics\n",
    "# Optimizer that implements the Adam algorithm - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "# SparseCategoricalCrossentropy computes the crossentropy loss between the labels and predictions. Use this function\n",
    "#   when there are two or more label classes. We expect labels to be provided as integers.\n",
    "# Accuracy calculates how often predictions equal labels.  \n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2421 - accuracy: 0.1845\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9408 - accuracy: 0.3404\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6788 - accuracy: 0.4033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5359 - accuracy: 0.4358\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3373 - accuracy: 0.5209\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1991 - accuracy: 0.5986\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1418 - accuracy: 0.6198\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0609 - accuracy: 0.6570\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9867 - accuracy: 0.6731\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.6912\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8829 - accuracy: 0.7245\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8544 - accuracy: 0.7265\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8017 - accuracy: 0.7525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7839 - accuracy: 0.7323\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.7865\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.7734\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.7994\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.8267\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.8484\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# x_train = Input data, numpy array\n",
    "# y_train = Target data, numpy array consistent with x\n",
    "# epochs = integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided.\n",
    "#           The model is not trained for a number of iterations given by epochs, but merely until the epoch of index\n",
    "#           epochs is reached.\n",
    "# batch_size = Integer or None. Number of samples per gradient update. \n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.6400\n"
     ]
    }
   ],
   "source": [
    "# Returns the loss value and metrics values for the model in test mode. Computation is done in batches.\n",
    "# X_test = Input data\n",
    "# y_test = Target data\n",
    "# batch_size = Number of samples per batch of computation. If unspecified, will default to 32.\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Test accuracy is 0.6400, which hits at Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating our approach\n",
    "\n",
    "# Let's set apart 200 samples in our training data to use as a validation set.\n",
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 2.2947 - accuracy: 0.1132 - val_loss: 2.1404 - val_accuracy: 0.3050\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.1178 - accuracy: 0.3462 - val_loss: 2.0014 - val_accuracy: 0.3200\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.9731 - accuracy: 0.3604 - val_loss: 1.8672 - val_accuracy: 0.3500\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.8193 - accuracy: 0.3643 - val_loss: 1.7511 - val_accuracy: 0.3600\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.6913 - accuracy: 0.4092 - val_loss: 1.6519 - val_accuracy: 0.3950\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.5653 - accuracy: 0.4753 - val_loss: 1.5631 - val_accuracy: 0.4350\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.4688 - accuracy: 0.5241 - val_loss: 1.4949 - val_accuracy: 0.4550\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.3799 - accuracy: 0.5324 - val_loss: 1.4330 - val_accuracy: 0.4900\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.3029 - accuracy: 0.5432 - val_loss: 1.3757 - val_accuracy: 0.5100\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.2292 - accuracy: 0.5723 - val_loss: 1.3560 - val_accuracy: 0.4950\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1746 - accuracy: 0.5963 - val_loss: 1.2992 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1055 - accuracy: 0.6101 - val_loss: 1.2797 - val_accuracy: 0.4950\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0571 - accuracy: 0.6287 - val_loss: 1.2602 - val_accuracy: 0.5050\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0020 - accuracy: 0.6420 - val_loss: 1.2315 - val_accuracy: 0.5350\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9554 - accuracy: 0.6833 - val_loss: 1.2097 - val_accuracy: 0.5600\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9245 - accuracy: 0.6839 - val_loss: 1.1771 - val_accuracy: 0.5650\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8884 - accuracy: 0.6927 - val_loss: 1.1527 - val_accuracy: 0.5700\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8517 - accuracy: 0.7059 - val_loss: 1.1464 - val_accuracy: 0.5750\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8176 - accuracy: 0.7162 - val_loss: 1.1333 - val_accuracy: 0.5650\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7855 - accuracy: 0.7436 - val_loss: 1.0923 - val_accuracy: 0.5850\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7521 - accuracy: 0.7575 - val_loss: 1.0655 - val_accuracy: 0.6200\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7170 - accuracy: 0.7769 - val_loss: 1.0961 - val_accuracy: 0.6100\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7063 - accuracy: 0.7895 - val_loss: 1.0849 - val_accuracy: 0.6100\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6773 - accuracy: 0.7862 - val_loss: 1.0484 - val_accuracy: 0.5950\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6504 - accuracy: 0.7833 - val_loss: 1.0300 - val_accuracy: 0.6500\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6260 - accuracy: 0.8106 - val_loss: 1.0372 - val_accuracy: 0.6500\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5936 - accuracy: 0.8190 - val_loss: 1.0641 - val_accuracy: 0.6450\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5795 - accuracy: 0.8115 - val_loss: 1.0515 - val_accuracy: 0.6500\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5357 - accuracy: 0.8501 - val_loss: 1.0639 - val_accuracy: 0.6100\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5372 - accuracy: 0.8468 - val_loss: 1.0928 - val_accuracy: 0.5850\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1721 - accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our network for 20 epochs\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.1720991134643555, 0.6000000238418579]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on Test Data\n",
    "# Predict - Generates output predictions for the input samples.\n",
    "#   Computation is done in batches.\n",
    "# X_test - Input samples, numpy array\n",
    "# batch_size - Number of samples per batch. If unspecified, will default to 32.\n",
    "predictions = model.predict(X_test)"
   ]
  }
 ]
}