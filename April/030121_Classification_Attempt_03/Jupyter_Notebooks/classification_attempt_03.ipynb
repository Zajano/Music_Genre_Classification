{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from pathlib import Path\n",
    "# import eyed3\n",
    "# import os\n",
    "# from config import *\n",
    "# import librosa\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from PIL import Image\n",
    "# import pathlib\n",
    "# import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "from keras import models, layers\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# eyed3.log.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     filename  chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n",
       "0  115384.mp3     0.360334  0.188969        2540.479255         2657.988433   \n",
       "1  115390.mp3     0.378215  0.225411        2269.649055         2558.470365   \n",
       "2  116882.mp3     0.295832  0.207426        2691.918208         2715.228839   \n",
       "3  020673.mp3     0.308657  0.194924        1049.751106          921.605218   \n",
       "4  048295.mp3     0.478366  0.265123        2264.178956         2776.148175   \n",
       "\n",
       "       rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  ...  \\\n",
       "0  5658.815782            0.079958  -37.924564   82.623207  -0.386473  ...   \n",
       "1  5142.127240            0.045125   -5.867516   93.227295  -1.638364  ...   \n",
       "2  5946.833547            0.093935  -28.662611   69.412605  -0.987070  ...   \n",
       "3  1869.794245            0.080677 -144.142548  211.651245 -61.986252  ...   \n",
       "4  5589.734312            0.061067  -83.822266   76.011131  20.975660  ...   \n",
       "\n",
       "     mfcc12     mfcc13    mfcc14    mfcc15    mfcc16    mfcc17    mfcc18  \\\n",
       "0  4.505314  -0.521939  4.845899 -0.166509  3.191389 -5.220356  0.609465   \n",
       "1  0.458813  -5.935056  1.049750 -4.718104  1.299657 -4.143320  1.892623   \n",
       "2 -3.122667 -13.669146 -6.803550 -7.937631  3.512264 -2.820511 -1.227399   \n",
       "3 -0.187126  -0.222602 -0.353398  3.233407  3.270443  1.799441  5.244574   \n",
       "4  4.302501  -0.057032  3.677136 -2.304578  2.451861 -2.614267  0.899178   \n",
       "\n",
       "      mfcc19    mfcc20     genre  \n",
       "0  -2.108234  3.528563  Chiptune  \n",
       "1  -3.189257  2.489733  Chiptune  \n",
       "2 -11.329582 -1.202103  Chiptune  \n",
       "3  -1.119697 -5.840265  Chiptune  \n",
       "4  -4.417268  2.062210  Chiptune  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>chroma_stft</th>\n      <th>rms</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc1</th>\n      <th>mfcc2</th>\n      <th>mfcc3</th>\n      <th>...</th>\n      <th>mfcc12</th>\n      <th>mfcc13</th>\n      <th>mfcc14</th>\n      <th>mfcc15</th>\n      <th>mfcc16</th>\n      <th>mfcc17</th>\n      <th>mfcc18</th>\n      <th>mfcc19</th>\n      <th>mfcc20</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>115384.mp3</td>\n      <td>0.360334</td>\n      <td>0.188969</td>\n      <td>2540.479255</td>\n      <td>2657.988433</td>\n      <td>5658.815782</td>\n      <td>0.079958</td>\n      <td>-37.924564</td>\n      <td>82.623207</td>\n      <td>-0.386473</td>\n      <td>...</td>\n      <td>4.505314</td>\n      <td>-0.521939</td>\n      <td>4.845899</td>\n      <td>-0.166509</td>\n      <td>3.191389</td>\n      <td>-5.220356</td>\n      <td>0.609465</td>\n      <td>-2.108234</td>\n      <td>3.528563</td>\n      <td>Chiptune</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>115390.mp3</td>\n      <td>0.378215</td>\n      <td>0.225411</td>\n      <td>2269.649055</td>\n      <td>2558.470365</td>\n      <td>5142.127240</td>\n      <td>0.045125</td>\n      <td>-5.867516</td>\n      <td>93.227295</td>\n      <td>-1.638364</td>\n      <td>...</td>\n      <td>0.458813</td>\n      <td>-5.935056</td>\n      <td>1.049750</td>\n      <td>-4.718104</td>\n      <td>1.299657</td>\n      <td>-4.143320</td>\n      <td>1.892623</td>\n      <td>-3.189257</td>\n      <td>2.489733</td>\n      <td>Chiptune</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>116882.mp3</td>\n      <td>0.295832</td>\n      <td>0.207426</td>\n      <td>2691.918208</td>\n      <td>2715.228839</td>\n      <td>5946.833547</td>\n      <td>0.093935</td>\n      <td>-28.662611</td>\n      <td>69.412605</td>\n      <td>-0.987070</td>\n      <td>...</td>\n      <td>-3.122667</td>\n      <td>-13.669146</td>\n      <td>-6.803550</td>\n      <td>-7.937631</td>\n      <td>3.512264</td>\n      <td>-2.820511</td>\n      <td>-1.227399</td>\n      <td>-11.329582</td>\n      <td>-1.202103</td>\n      <td>Chiptune</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>020673.mp3</td>\n      <td>0.308657</td>\n      <td>0.194924</td>\n      <td>1049.751106</td>\n      <td>921.605218</td>\n      <td>1869.794245</td>\n      <td>0.080677</td>\n      <td>-144.142548</td>\n      <td>211.651245</td>\n      <td>-61.986252</td>\n      <td>...</td>\n      <td>-0.187126</td>\n      <td>-0.222602</td>\n      <td>-0.353398</td>\n      <td>3.233407</td>\n      <td>3.270443</td>\n      <td>1.799441</td>\n      <td>5.244574</td>\n      <td>-1.119697</td>\n      <td>-5.840265</td>\n      <td>Chiptune</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>048295.mp3</td>\n      <td>0.478366</td>\n      <td>0.265123</td>\n      <td>2264.178956</td>\n      <td>2776.148175</td>\n      <td>5589.734312</td>\n      <td>0.061067</td>\n      <td>-83.822266</td>\n      <td>76.011131</td>\n      <td>20.975660</td>\n      <td>...</td>\n      <td>4.302501</td>\n      <td>-0.057032</td>\n      <td>3.677136</td>\n      <td>-2.304578</td>\n      <td>2.451861</td>\n      <td>-2.614267</td>\n      <td>0.899178</td>\n      <td>-4.417268</td>\n      <td>2.062210</td>\n      <td>Chiptune</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 359
    }
   ],
   "source": [
    "# Analysing the data in Pandas\n",
    "data_raw = pd.read_csv(f'{genre_csvs_path}/all_genres_csv.csv')\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 360
    }
   ],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping filename column\n",
    "data_no_filenames = data_raw.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334, 27)"
      ]
     },
     "metadata": {},
     "execution_count": 362
    }
   ],
   "source": [
    "data_no_filenames.shape\n",
    "#data_no_filenames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n0        0.360334  0.188969        2540.479255         2657.988433   \n1        0.378215  0.225411        2269.649055         2558.470365   \n2        0.295832  0.207426        2691.918208         2715.228839   \n3        0.308657  0.194924        1049.751106          921.605218   \n4        0.478366  0.265123        2264.178956         2776.148175   \n...           ...       ...                ...                 ...   \n8329     0.395774  0.120443        2058.111948         1851.790386   \n8330     0.444157  0.318770        2117.818866         2310.499874   \n8331     0.299300  0.108959        2102.942517         1539.198952   \n8332     0.399944  0.102906        1626.045612         1678.233277   \n8333     0.437711  0.231284        2131.379182         2197.591764   \n\n          rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  \\\n0     5658.815782            0.079958  -37.924564   82.623207  -0.386473   \n1     5142.127240            0.045125   -5.867516   93.227295  -1.638364   \n2     5946.833547            0.093935  -28.662611   69.412605  -0.987070   \n3     1869.794245            0.080677 -144.142548  211.651245 -61.986252   \n4     5589.734312            0.061067  -83.822266   76.011131  20.975660   \n...           ...                 ...         ...         ...        ...   \n8329  4127.086069            0.102327 -127.137100  111.435501 -47.977318   \n8330  4571.594096            0.079500  -14.357430   92.445580 -11.426455   \n8331  3710.752562            0.141197 -145.987289  106.740822 -76.398895   \n8332  3203.001417            0.082065 -147.359268  132.290649 -47.646404   \n8333  4053.204332            0.118057    0.629772  100.701263 -28.042839   \n\n          mfcc4      mfcc5      mfcc6      mfcc7      mfcc8     mfcc9  \\\n0     15.709459  -4.471007   3.997032  -4.278410   4.517568 -1.889164   \n1     18.842438  -1.776895   6.304925  -5.125690   3.424945 -4.477562   \n2     24.394915  -7.282684   1.544695 -10.475027  -0.510076 -9.776934   \n3      8.561708   0.965559 -16.381641  -6.581376  -6.376841 -5.098131   \n4     30.706326  12.202972  16.030960   3.973017  13.773401  3.777658   \n...         ...        ...        ...        ...        ...       ...   \n8329  75.184212 -22.696707  24.367685  18.880646   8.748158 -5.166871   \n8330  46.390846   6.423421  19.648289   7.560176  13.143040  2.756235   \n8331  50.790901 -28.908426  11.970723  -6.074793   3.018739  6.450067   \n8332  50.317703   6.456532   7.903978  -7.491793  -1.870585  0.156245   \n8333  31.271770  12.105971   2.884447  -2.459609  17.873400 -5.083400   \n\n         mfcc10    mfcc11     mfcc12     mfcc13     genre  \n0      4.253541 -1.343986   4.505314  -0.521939  Chiptune  \n1      2.307881 -6.097126   0.458813  -5.935056  Chiptune  \n2     -2.753444 -8.789730  -3.122667 -13.669146  Chiptune  \n3     -2.851786  0.866325  -0.187126  -0.222602  Chiptune  \n4      5.631431  0.448347   4.302501  -0.057032  Chiptune  \n...         ...       ...        ...        ...       ...  \n8329   0.630253  1.424852  -1.794622   0.303786     Metal  \n8330   5.271970  0.049521   4.239135  -5.215909     Metal  \n8331  -4.460278 -5.503634 -10.813322 -10.830860     Metal  \n8332 -10.263104 -1.823900   3.712788  -5.213496     Metal  \n8333  10.628754  3.232105   4.266963  -1.843944     Metal  \n\n[8334 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create three data sets, data_no_filenames, data_mfccs_only, and data_feat_mfccs\n",
    "# CLASSIFICATION first features + MFCCs 1-13 only\n",
    "# Remove mfcss over 13, retain genre column\n",
    "mfcc = 'mfcc'\n",
    "mfcc_list = [mfcc+str(x) for x in list(range(13+1 ,20+1))]\n",
    "data_mfccs_plus = data_no_filenames.drop(mfcc_list, axis=1)\n",
    "data_mfccs_plus.shape\n",
    "print(data_mfccs_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334,)"
      ]
     },
     "metadata": {},
     "execution_count": 364
    }
   ],
   "source": [
    "# Encoding the genres into numbers\n",
    "genres_list = data_mfccs_plus.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "genres_y = encoder.fit_transform(genres_list)\n",
    "genres_y.shape\n",
    "# print(genres_y)\n",
    "# Just checking to see the original genres\n",
    "#print(encoder.inverse_transform(genres_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 365
    }
   ],
   "source": [
    "# Get mfccs only\n",
    "data_mfccs_only = data_mfccs_plus.iloc[:,data_mfccs_plus.columns.get_loc('mfcc1'):]\n",
    "data_mfccs_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 366
    }
   ],
   "source": [
    "# Get first six features and mfcc2 only\n",
    "mfcc2_drop = [mfcc+str(x) for x in list(range(2+1 ,13+1))]\n",
    "data_feat_mfcc2 = data_mfccs_plus.drop(mfcc2_drop,axis=1)\n",
    "data_feat_mfcc2 = data_feat_mfcc2.drop('mfcc1',axis=1)\n",
    "data_feat_mfcc2.shape\n",
    "#print(data_feat_mfcc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334, 26)"
      ]
     },
     "metadata": {},
     "execution_count": 367
    }
   ],
   "source": [
    "# Scaling the Feature Columns \n",
    "# a. All\n",
    "scaler = StandardScaler()\n",
    "features_X_a = scaler.fit_transform(np.array(data_no_filenames.iloc[:, :-1], dtype=float))\n",
    "features_X_a.shape\n",
    "#print(features_X_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 8.00164743e-01 -6.79844685e-01  5.39432988e-02 ...  3.62237406e-01\n   3.49199914e-01  5.43141334e-01]\n [ 1.10827977e+00 -3.76665767e-01 -2.30739662e-04 ... -4.56610201e-01\n  -3.64791492e-01 -4.97253381e-01]\n [ 8.89185633e-01 -1.05754581e+00  2.79532110e-02 ... -9.20478943e-01\n  -9.96731409e-01 -1.98373640e+00]\n ...\n [-2.38475773e-01  9.69622147e-03 -3.23540036e+00 ... -3.54366378e-01\n  -2.35372127e+00 -1.43822126e+00]\n [-2.51662491e-01  7.40185179e-01 -1.99117184e+00 ...  2.79560239e-01\n   2.09361318e-01 -3.58570393e-01]\n [ 1.17072819e+00 -1.62979336e-01 -1.14285177e+00 ...  1.15058401e+00\n   3.07143548e-01  2.89053491e-01]]\n"
     ]
    }
   ],
   "source": [
    "# b. MFCCS 1-13 only\n",
    "scaler = StandardScaler()\n",
    "features_X_b = scaler.fit_transform(np.array(data_mfccs_only.iloc[:, :-1], dtype=float))\n",
    "features_X_b.shape\n",
    "print(features_X_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8334, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 369
    }
   ],
   "source": [
    "# c. First six features and mfcc2 only\n",
    "scaler = StandardScaler()\n",
    "features_X_c = scaler.fit_transform(np.array(data_feat_mfcc2.iloc[:, :-1], dtype=float))\n",
    "features_X_c.shape\n",
    "#print(features_X_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION ALL FEATURES\n",
    "# Dividing data into training and Testing set\n",
    "# Test a\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(features_X_a, genres_y, test_size=0.2)\n",
    "# Test b\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(features_X_b, genres_y, test_size=0.2)\n",
    "# Test c\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(features_X_c, genres_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6667 6667 6667\n1667 1667 1667\n6667 6667 6667\n1667 1667 1667\n8334\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_a), len(X_train_b), len(X_train_c))\n",
    "print(len(X_test_a), len(X_test_b), len(X_test_c))\n",
    "print(len(y_train_a), len(y_train_b), len(y_train_c))\n",
    "print(len(y_test_a), len(y_test_b), len(y_test_c))\n",
    "print(len(genres_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification with Keras\n",
    "# Relu - Applies the rectified linear unit activation function.\n",
    "# With default values, this returns the standard ReLU activation: max(x, 0), the element-wise maximum of 0 and the input tensor.\n",
    "# https://keras.io/api/layers/activations/\n",
    "# Softmax - The softmax function, also known as softargmax[1]:184 or normalized exponential function,[2]:198 is a generalization of the logistic \n",
    "# function to multiple dimensions. It is used in multinomial logistic regression and is often used as the last activation function of a neural \n",
    "# network to normalize the output of a network to a probability distribution over predicted output classes, based on Luce's choice axiom.\n",
    "# https://en.wikipedia.org/wiki/Softmax_function\n",
    "\n",
    "# Building our Networks\n",
    "# A\n",
    "modelA = models.Sequential()\n",
    "modelA.add(layers.Dense(512, activation='relu', input_shape=(X_train_a.shape[1],)))\n",
    "modelA.add(layers.Dense(256, activation='relu'))\n",
    "modelA.add(layers.Dense(128, activation='relu'))\n",
    "modelA.add(layers.Dense(64, activation='relu'))\n",
    "modelA.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "# B\n",
    "modelB = models.Sequential()\n",
    "modelB.add(layers.Dense(512, activation='relu', input_shape=(X_train_b.shape[1],)))\n",
    "modelB.add(layers.Dense(256, activation='relu'))\n",
    "modelB.add(layers.Dense(128, activation='relu'))\n",
    "modelB.add(layers.Dense(64, activation='relu'))\n",
    "modelB.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "# C\n",
    "modelC = models.Sequential()\n",
    "modelC.add(layers.Dense(512, activation='relu', input_shape=(X_train_c.shape[1],)))\n",
    "modelC.add(layers.Dense(256, activation='relu'))\n",
    "modelC.add(layers.Dense(128, activation='relu'))\n",
    "modelC.add(layers.Dense(64, activation='relu'))\n",
    "modelC.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config the model with losses and metrics\n",
    "# Optimizer that implements the Adam algorithm - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "# SparseCategoricalCrossentropy computes the crossentropy loss between the labels and predictions. Use this function\n",
    "#   when there are two or more label classes. We expect labels to be provided as integers.\n",
    "# Accuracy calculates how often predictions equal labels.  \n",
    "modelA.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelB.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelC.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set epochs\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 1s 3ms/step - loss: 2.4856 - accuracy: 0.2959\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7513 - accuracy: 0.4623\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.6250 - accuracy: 0.4982\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.5022 - accuracy: 0.5331\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.4571 - accuracy: 0.5368\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.3571 - accuracy: 0.5604\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.3083 - accuracy: 0.5809\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.6078\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.2196 - accuracy: 0.6146\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.1522 - accuracy: 0.6279\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.1140 - accuracy: 0.6371\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.0563 - accuracy: 0.6560\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.9883 - accuracy: 0.6816\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.9488 - accuracy: 0.6993\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.9155 - accuracy: 0.7011\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.8317 - accuracy: 0.7387\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.7546\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.7713\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7322 - accuracy: 0.7588\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7847\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# x_train = Input data, numpy array\n",
    "# y_train = Target data, numpy array consistent with x\n",
    "# epochs = integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided.\n",
    "#           The model is not trained for a number of iterations given by epochs, but merely until the epoch of index\n",
    "#           epochs is reached.\n",
    "# batch_size = Integer or None. Number of samples per gradient update. \n",
    "historyA = modelA.fit(X_train_a, y_train_a, epochs=epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 1s 3ms/step - loss: 2.5739 - accuracy: 0.2777\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.9357 - accuracy: 0.4101\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8800 - accuracy: 0.4211\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.8260 - accuracy: 0.4309\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7527 - accuracy: 0.4468\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7010 - accuracy: 0.4629\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.6723 - accuracy: 0.4778\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.6562 - accuracy: 0.4750\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.6086 - accuracy: 0.4952\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.5757 - accuracy: 0.5017\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.5098 - accuracy: 0.5153\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.5231 - accuracy: 0.5185\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.5077 - accuracy: 0.5177\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.4333 - accuracy: 0.5441\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.3949 - accuracy: 0.5462\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.3457 - accuracy: 0.5724\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.3059 - accuracy: 0.5918\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.3030 - accuracy: 0.5773\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.2986 - accuracy: 0.5843\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.2430 - accuracy: 0.6022\n"
     ]
    }
   ],
   "source": [
    "historyB = modelB.fit(X_train_b, y_train_b, epochs=epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 1s 3ms/step - loss: 2.6714 - accuracy: 0.2706\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.1739 - accuracy: 0.3683\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.0440 - accuracy: 0.3900\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.0489 - accuracy: 0.3698\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.9965 - accuracy: 0.3850\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.9853 - accuracy: 0.3942\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.3964\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.9216 - accuracy: 0.4119\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9205 - accuracy: 0.4105\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8820 - accuracy: 0.4204\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.9109 - accuracy: 0.4073\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8600 - accuracy: 0.4322\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8315 - accuracy: 0.4363\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8659 - accuracy: 0.4089\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8223 - accuracy: 0.4415\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7951 - accuracy: 0.4490\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8079 - accuracy: 0.4380\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7850 - accuracy: 0.4563\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7781 - accuracy: 0.4411\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7526 - accuracy: 0.4573\n"
     ]
    }
   ],
   "source": [
    "historyC = modelC.fit(X_train_c, y_train_c, epochs=epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss A:  1.797038197517395\nTest loss B:  1.794525146484375\nTest loss C:  1.888838529586792\nTest accuracy A:  0.5134972929954529\nTest accuracy B:  0.47150570154190063\nTest accuracy C:  0.42111578583717346\n"
     ]
    }
   ],
   "source": [
    "# Returns the loss value and metrics values for the model in test mode. Computation is done in batches.\n",
    "# X_test = Input data\n",
    "# y_test = Target data\n",
    "# batch_size = Number of samples per batch of computation. If unspecified, will default to 32.\n",
    "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "testA = modelA.evaluate(X_test_a, y_test_a, verbose=0)\n",
    "testB = modelB.evaluate(X_test_b, y_test_b, verbose=0)\n",
    "testC = modelC.evaluate(X_test_c, y_test_c, verbose=0)\n",
    " \n",
    "print('Test loss A: ', testA[0])\n",
    "print('Test loss B: ', testB[0])\n",
    "print('Test loss C: ', testC[0])\n",
    "\n",
    "print('Test accuracy A: ', testA[1])\n",
    "print('Test accuracy B: ', testB[1])\n",
    "print('Test accuracy C: ', testC[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating approach\n",
    "# Set apart 200 samples in training data to use as validation set\n",
    "x_val_a = X_train_a[:200]\n",
    "x_val_b = X_train_b[:200]\n",
    "x_val_c = X_train_c[:200]\n",
    "partial_x_train_a = X_train_a[200:]\n",
    "partial_x_train_b = X_train_b[200:]\n",
    "partial_x_train_c = X_train_c[200:]\n",
    "\n",
    "y_val_a = y_train_a[:200]\n",
    "y_val_b = y_train_b[:200]\n",
    "y_val_c = y_train_c[:200]\n",
    "partial_y_train_a = y_train_a[200:]\n",
    "partial_y_train_b = y_train_b[200:]\n",
    "partial_y_train_c = y_train_c[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train network for epochs = 20\n",
    "# Building our Networks\n",
    "# A\n",
    "modelA = models.Sequential()\n",
    "modelA.add(layers.Dense(512, activation='relu', input_shape=(X_train_a.shape[1],)))\n",
    "modelA.add(layers.Dense(256, activation='relu'))\n",
    "modelA.add(layers.Dense(128, activation='relu'))\n",
    "modelA.add(layers.Dense(64, activation='relu'))\n",
    "modelA.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "# B\n",
    "modelB = models.Sequential()\n",
    "modelB.add(layers.Dense(512, activation='relu', input_shape=(X_train_b.shape[1],)))\n",
    "modelB.add(layers.Dense(256, activation='relu'))\n",
    "modelB.add(layers.Dense(128, activation='relu'))\n",
    "modelB.add(layers.Dense(64, activation='relu'))\n",
    "modelB.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "# C\n",
    "modelC = models.Sequential()\n",
    "modelC.add(layers.Dense(512, activation='relu', input_shape=(X_train_c.shape[1],)))\n",
    "modelC.add(layers.Dense(256, activation='relu'))\n",
    "modelC.add(layers.Dense(128, activation='relu'))\n",
    "modelC.add(layers.Dense(64, activation='relu'))\n",
    "modelC.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "modelA.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelB.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelC.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'partial_y_train_a' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-22b9f5f231db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistoryA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_x_train_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial_y_train_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresultsA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultsA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partial_y_train_a' is not defined"
     ]
    }
   ],
   "source": [
    "historyA = modelA.fit(partial_x_train_a, partial_y_train_a, epochs=epochs, batch_size=512, validation_data=(x_val_a, y_val_a))\n",
    "resultsA = modelA.evaluate(X_test_a, y_test_a)\n",
    "print(resultsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyB = modelB.fit(partial_x_train_b, partial_y_train_b, epochs=epochs, batch_size=512, validation_data=(x_val_b, y_val_b))\n",
    "resultsB = modelB.evaluate(X_test_b, y_test_b)\n",
    "print(resultsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyC = modelC.fit(partial_x_train_c, partial_y_train_c, epochs=epochs, batch_size=512, validation_data=(x_val_c, y_val_c))\n",
    "resultsC = modelC.evaluate(X_test_c, y_test_c)\n",
    "print(resultsC)"
   ]
  }
 ]
}